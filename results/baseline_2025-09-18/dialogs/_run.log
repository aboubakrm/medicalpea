[LOAD] scenarios=10
[SCENARIO] D01 / experience
[LLM] Using model=gpt-4.1
[WROTE] results/dialogs/D01.csv and results/dialogs/D01.md
[SCENARIO] D02 / realism
[LLM] Using model=gpt-4.1
[WROTE] results/dialogs/D02.csv and results/dialogs/D02.md
[SCENARIO] D03 / compliance
[LLM] Using model=gpt-4.1
[WROTE] results/dialogs/D03.csv and results/dialogs/D03.md
[SCENARIO] D04 / realism
[LLM] Using model=gpt-4.1
[WROTE] results/dialogs/D04.csv and results/dialogs/D04.md
[SCENARIO] D05 / realism
[LLM] Using model=gpt-4.1
[WROTE] results/dialogs/D05.csv and results/dialogs/D05.md
[SCENARIO] D06 / experience
[LLM] Using model=gpt-4.1
[ERROR turn 1] RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-HP7ALuaC5odLnE98cWmdBVv8 on tokens per min (TPM): Limit 30000, Used 27979, Requested 2151. Please try again in 260ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/Users/aboubakrsaleh/Documents/GitHub/medicalpea/src/run_dialog_demo.py", line 90, in run_dialog
    reply = llm.invoke(msgs).content
            ^^^^^^^^^^^^^^^^
  File "/Users/aboubakrsaleh/Documents/GitHub/medicalpea/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 395, in invoke
    self.generate_prompt(
  File "/Users/aboubakrsaleh/Documents/GitHub/medicalpea/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 1023, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/aboubakrsaleh/Documents/GitHub/medicalpea/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 840, in generate
    self._generate_with_cache(
  File "/Users/aboubakrsaleh/Documents/GitHub/medicalpea/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 1089, in _generate_with_cache
    result = self._generate(
             ^^^^^^^^^^^^^^^
  File "/Users/aboubakrsaleh/Documents/GitHub/medicalpea/.venv/lib/python3.12/site-packages/langchain_openai/chat_models/base.py", line 717, in _generate
    response = self.client.create(**payload)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/aboubakrsaleh/Documents/GitHub/medicalpea/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/aboubakrsaleh/Documents/GitHub/medicalpea/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 1147, in create
    return self._post(
           ^^^^^^^^^^^
  File "/Users/aboubakrsaleh/Documents/GitHub/medicalpea/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/aboubakrsaleh/Documents/GitHub/medicalpea/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1047, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-HP7ALuaC5odLnE98cWmdBVv8 on tokens per min (TPM): Limit 30000, Used 27979, Requested 2151. Please try again in 260ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}

[WROTE] results/dialogs/D06.csv and results/dialogs/D06.md
[SCENARIO] D07 / realism
[LLM] Using model=gpt-4.1
[WROTE] results/dialogs/D07.csv and results/dialogs/D07.md
[SCENARIO] D08 / realism
[LLM] Using model=gpt-4.1
[WROTE] results/dialogs/D08.csv and results/dialogs/D08.md
[SCENARIO] D09 / sales_training
[LLM] Using model=gpt-4.1
[WROTE] results/dialogs/D09.csv and results/dialogs/D09.md
[SCENARIO] D10 / compliance
[LLM] Using model=gpt-4.1
[WROTE] results/dialogs/D10.csv and results/dialogs/D10.md
[DONE] See results/dialogs/*.md and *.csv; check _run.log for details.
